{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q.1-  What is Simple Linear Regression (SLR)? Explain its purpose.\n",
        "- Simple Linear Regression (SLR) is a statistical and machine learning technique used to model the relationship between one independent variable (X) and one dependent variable (Y) by fitting a straight line to the observed data.\n",
        "\n",
        "Purpose of Simple Linear Regression\n",
        "\n",
        "The main purposes of SLR are:\n",
        "\n",
        "To understand relationships\n",
        "It helps determine whether there is a linear relationship between two variables and how strong that relationship is.\n",
        "\n",
        "To quantify the effect of X on Y\n",
        "The slope (ğ›½1) explains how much the dependent variable changes when the independent variable increases by one unit.\n",
        "\n",
        "To make predictions\n",
        "Once the model is fitted, it can be used to predict future or unseen values of Y based on given values of X.\n",
        "\n",
        "To explain trends in data\n",
        "SLR summarizes data trends using a simple equation, making it easier to interpret and communicate results."
      ],
      "metadata": {
        "id": "fwss6dYPEmWl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.2- What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "Key Assumptions of Simple Linear Regression (SLR)\n",
        "\n",
        "For Simple Linear Regression to produce reliable and valid results, the following assumptions must hold:\n",
        "\n",
        "1. Linearity\n",
        "\n",
        "The relationship between the independent variable (X) and the dependent variable (Y) is linear.\n",
        "\n",
        "This means the expected value of Y can be expressed as a straight-line function of X.\n",
        "\n",
        "\n",
        "2. Independence of Errors\n",
        "\n",
        "The residuals (errors) are independent of each other.\n",
        "\n",
        "No correlation exists between consecutive error terms.\n",
        "\n",
        "\n",
        "3. Homoscedasticity (Constant Variance)\n",
        "\n",
        "The residuals have constant variance across all values of X.\n",
        "\n",
        "The spread of residuals should be roughly the same along the regression line.\n",
        "\n",
        "\n",
        "4. Normality of Errors\n",
        "\n",
        "The residuals are normally distributed with a mean of zero.\n",
        "\n",
        "Important mainly for hypothesis testing and confidence intervals.\n",
        "\n",
        "5. No Perfect Multicollinearity\n",
        "\n",
        "Since SLR has only one predictor, this assumption is automatically satisfied.\n",
        "\n",
        "It becomes relevant in multiple linear regression."
      ],
      "metadata": {
        "id": "o5DtUC2rFMjU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.3- Write the mathematical equation for a simple linear regression model and explain each term.\n",
        "- Mathematical Equation of Simple Linear Regression\n",
        "\n",
        "The simple linear regression (SLR) model is mathematically represented as:\n",
        "\n",
        "Y=\n",
        "ğ›½0 +ğ›½1ğ‘‹ +ğœ€\n",
        "\n",
        "Explanation of Each Term\n",
        "\n",
        "Y â€” Dependent (response) variable\n",
        "The outcome you want to predict or explain (e.g., salary, sales, price).\n",
        "\n",
        "X â€” Independent (predictor) variable\n",
        "The input variable used to explain or predict Y (e.g., experience, time, size).\n",
        "\n",
        "ğ›½0(Intercept)\n",
        "The expected value of Y when X=0\n",
        "It represents where the regression line intersects the Y-axis.\n",
        "\n",
        "ğ›½1(Slope / Regression Coefficient)\n",
        "The change in Y for a one-unit increase in X.\n",
        "\n",
        "If\n",
        "ğ›½1>0: positive relationship\n",
        "\n",
        "If\n",
        "ğ›½1<0: negative relationship\n",
        "\n",
        "Îµ (Error Term)\n",
        "Captures the random variation in Y that cannot be explained by X.\n",
        "Accounts for noise, measurement errors, and unobserved factors."
      ],
      "metadata": {
        "id": "_Jz-CAmDFqn8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.4-Provide a real-world example where simple linear regression can be\n",
        "applied.\n",
        "xample: Predicting Salary Based on Years of Experience\n",
        "\n",
        "A company wants to estimate an employeeâ€™s annual salary (Y) based on their years of work experience (X).\n",
        "\n",
        "Why Simple Linear Regression Fits\n",
        "\n",
        "There is one predictor (years of experience).\n",
        "\n",
        "Salary generally increases in a linear manner with experience.\n",
        "\n",
        "The goal is to predict salary and understand the relationship.\n",
        "\n",
        "Model Representation\n",
        "Salary =ğ›½0+ğ›½1*Experience+ğœ€\n",
        "\n",
        "Where:\n",
        "\n",
        "ğ›½0= starting salary (when experience is 0 years)\n",
        "\n",
        "ğ›½1= average salary increase per additional year of experience\n",
        "\n",
        "Îµ = unexplained variation\n",
        "\n",
        "Interpretation\n",
        "\n",
        "If the fitted model is:\n",
        "Salary=3+1.5Ã—Experience\n",
        "\n",
        "Then:\n",
        "\n",
        "A fresher (0 years experience) earns â‚¹3 lakh\n",
        "\n",
        "Each additional year of experience increases salary by â‚¹1.5 lakh"
      ],
      "metadata": {
        "id": "MEd9yK9NHG5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.5-What is the method of least squares in linear regression?\n",
        "- The method of least squares is a mathematical technique used to estimate the parameters of a linear regression model (intercept and slope) so that the model best fits the observed data.\n",
        "\n",
        "Core Idea\n",
        "\n",
        "It chooses the regression line such that the sum of the squared residuals (errors) between the observed values and the predicted values is minimized."
      ],
      "metadata": {
        "id": "1wuW5p02H82w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "q.6-What is Logistic Regression? How does it differ from Linear Regression?\n",
        "- Logistic Regression is a supervised learning algorithm mainly used for classification problems, especially binary classification. Instead of predicting a continuous value, it predicts the probability that an observation belongs to a particular class (such as 0 or 1). It uses the sigmoid (logistic) function to convert a linear combination of input variables into a value between 0 and 1.\n",
        "How Logistic Regression Differs from Linear Regression\n",
        "\n",
        "The main difference lies in what they predict. Linear regression predicts a continuous numerical value, such as price or salary, while logistic regression predicts a probability used for classification, such as whether an email is spam or not.\n",
        "\n",
        "Linear regression uses a straight-line equation and can produce any real value from negative to positive infinity. Logistic regression, on the other hand, passes the linear equation through a sigmoid function, ensuring outputs stay between 0 and 1.\n",
        "\n",
        "Another key difference is in how errors are measured. Linear regression minimizes the sum of squared errors, whereas logistic regression uses log loss (cross-entropy), which is better suited for probability-based classification tasks.\n",
        "\n",
        "Finally, linear regression assumes normally distributed errors and constant variance, while logistic regression does not require these assumptions, making it more suitable for classification problems.\n",
        "\n",
        "Example\n",
        "\n",
        "If you want to predict house prices, linear regression is appropriate.\n",
        "If you want to predict whether a customer will buy a product (yes/no), logistic regression is the correct choice."
      ],
      "metadata": {
        "id": "YbfNOj5GIl5s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "q-7. Name and briefly describe three common evaluation metrics for regression models.\n",
        "- Three Common Evaluation Metrics for Regression Models\n",
        "\n",
        "Mean Squared Error (MSE)\n",
        "Mean Squared Error measures the average of the squared differences between actual and predicted values. Squaring penalizes larger errors more heavily, making MSE sensitive to outliers. Lower MSE indicates a better-fitting model.\n",
        "\n",
        "Root Mean Squared Error (RMSE)\n",
        "Root Mean Squared Error is the square root of MSE, which brings the error back to the same units as the target variable. It is easier to interpret than MSE and reflects how far predictions are from actual values on average.\n",
        "\n",
        "Mean Absolute Error (MAE)\n",
        "Mean Absolute Error calculates the average of the absolute differences between actual and predicted values. It treats all errors equally and is less sensitive to outliers compared to MSE and RMSE."
      ],
      "metadata": {
        "id": "s10e9nRxI6Nv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "q.8- What is the purpose of the R-squared metric in regression analysis?\n",
        "- R-squared (RÂ²) is used to measure how well a regression model explains the variability of the dependent variable.\n",
        "\n",
        "In simple terms, it tells us what proportion of the total variation in the output variable is explained by the model using the input variables.\n",
        "\n",
        "Key Purposes of R-squared\n",
        "\n",
        "Explains model fit\n",
        "RÂ² indicates how well the regression line fits the data. A higher RÂ² means the model explains more of the variation in the target variable.\n",
        "\n",
        "Measures explanatory power\n",
        "It quantifies the strength of the relationship between predictors and the response variable.\n",
        "\n",
        "Helps compare models\n",
        "RÂ² can be used to compare different regression models on the same dataset (though adjusted RÂ² is preferred when the number of predictors differs)."
      ],
      "metadata": {
        "id": "QkZNvreIKaAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.9\n",
        "# Import required libraries\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Sample data\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)  # Independent variable\n",
        "y = np.array([2, 4, 5, 4, 6])                # Dependent variable\n",
        "\n",
        "# Create and train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Get slope and intercept\n",
        "slope = model.coef_[0]\n",
        "intercept = model.intercept_\n",
        "\n",
        "# Print results\n",
        "print(\"Slope:\", slope)\n",
        "print(\"Intercept:\", intercept)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1XG6P-XK7sl",
        "outputId": "307c8a9c-a9d4-47e7-9659-5d1bffe6cd75"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope: 0.8000000000000002\n",
            "Intercept: 1.7999999999999998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.10-\n",
        "A simple linear regression model is written as:\n",
        "Y=Î²0+Î²1X+Îµ\n",
        "\n",
        "Each coefficient has a clear and practical interpretation.\n",
        "\n",
        "1. Intercept (ğ›½0)\n",
        "\n",
        "The intercept represents the expected value of the dependent variable\n",
        "Y when the independent variable X is zero.\n",
        "\n",
        "It is the point where the regression line cuts the Y-axis.\n",
        "\n",
        "In some real-world cases,\n",
        "X=0 may not be meaningful, but the intercept is still required to position the regression line correctly.\n",
        "\n",
        "Example:\n",
        "If Î²0=10, then when X=0, the predicted value of Y is 10.\n",
        "\n",
        "2. Slope (ğ›½1)\n",
        "\n",
        "The slope represents the average change in\n",
        "Y for a one-unit increase in X.\n",
        "\n",
        "It indicates the direction and strength of the relationship:\n",
        "\n",
        "ğ›½1>0: Positive relationship (Y increases as X increases)\n",
        "\n",
        "ğ›½1<0: Negative relationship (Y decreases as X increases)\n",
        "\n",
        "ğ›½1=0: No linear relationship"
      ],
      "metadata": {
        "id": "HvWYexYgLGkM"
      }
    }
  ]
}